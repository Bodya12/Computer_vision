{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Structure*:\n",
    "\n",
    "* data [ folder 'data' ] \n",
    "* scripts [ folder 'src' ] \n",
    "\n",
    "*Colormap of the notebook:*\n",
    "\n",
    "* <span style=\"color:red\">assignment problem</span>. The red color indicates the task that should be done\n",
    "* <span style=\"color:green\">debugging</span>. The green tells you what is expected outcome. Its primarily goal to help you get the correct answer\n",
    "* <span style=\"color:blue\">comments</span>.\n",
    "\n",
    "Assignment 4 (Convolutional Neural Network)\n",
    "======================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch supports many layer types, loss functions, and optimizers\n",
    "\n",
    "* Layers: http://pytorch.org/docs/nn.html\n",
    "* Activations: http://pytorch.org/docs/nn.html#non-linear-activations\n",
    "* Loss functions: http://pytorch.org/docs/nn.html#loss-functions\n",
    "* Optimizers: http://pytorch.org/docs/optim.html#algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for compatability issues \n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to make interactive plotting possible\n",
    "%matplotlib inline\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make plots a bit nicer\n",
    "plt.matplotlib.rcParams.update({'font.size': 18, 'font.family': 'serif'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random seed settings\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# data type (useful to have in pytorch)\n",
    "dtype_np = np.float64\n",
    "dtype_torch = torch.FloatTensor\n",
    "dtype_torch_cuda = torch.cuda.FloatTensor # to run on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.data_set import DataSetCifar10, DataSetDTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andrey/LDSSS2017/assigments/data\r\n",
      "file exists\r\n"
     ]
    }
   ],
   "source": [
    "!./data/get_cifar10_dataset.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data = 'data' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_set = DataSetCifar10(path_data, num_dunkeys=4, batch_size=batch_size)\n",
    "#data_set = DataSetDTD(path_data, num_dunkeys=4, batch_size=100, fin_scale=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_test(data_loader, model_current, train_test, gpu=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images_, labels_ in data_loader[train_test]:\n",
    "        \n",
    "        if gpu:\n",
    "            images_ = Variable(images_.type(dtype_torch_cuda), volatile=True)\n",
    "            outputs_ = model_current(images_)\n",
    "            _, predicted = torch.max(outputs_.data.cpu(), 1)\n",
    "        else:\n",
    "            images_ = Variable(images_)\n",
    "            outputs_ = model_current(images_)\n",
    "            _, predicted = torch.max(outputs_.data, 1)\n",
    "            \n",
    "        total += labels_.size(0)\n",
    "        correct += (predicted == labels_).sum()\n",
    "    print('accuracy[' + train_test + '] : %f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten function, which we explain here. Remember that our image data (and more relevantly, our intermediate feature maps) are initially N x C x H x W, where:\n",
    "* N is the number of datapoints\n",
    "* C is the number of channels\n",
    "* H is the height of the intermediate feature map in pixels\n",
    "* W is the height of the intermediate feature map in pixels\n",
    "\n",
    "This is the right way to represent the data when we are doing something like a 2D convolution, that needs spatial understanding of where the intermediate features are relative to each other. When we input  data into fully connected affine layers, however, we want each datapoint to be represented by a single vector -- it's no longer useful to segregate the different channels, rows, and columns of the data. So, we use a \"Flatten\" operation to collapse the C x H x W values per representation into a single long vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential (\n",
       "  (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2))\n",
       "  (1): ReLU (inplace)\n",
       "  (2): Flatten (\n",
       "  )\n",
       "  (3): Linear (5408 -> 10)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's where we define the architecture of the model... \n",
    "first_model = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, kernel_size=7, stride=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                Flatten(), # see above for explanation\n",
    "                nn.Linear(5408, 10), # affine layer\n",
    "              )\n",
    "\n",
    "# Set the type of all data in this model to be FloatTensor \n",
    "first_model.type(dtype_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = copy.deepcopy(first_model).type(dtype_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().type(dtype_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: [1/1], step: [100/500], loss: 1.8933\n",
      "epoch: [1/1], step: [200/500], loss: 1.5111\n",
      "epoch: [1/1], step: [300/500], loss: 1.4503\n",
      "epoch: [1/1], step: [400/500], loss: 1.5622\n",
      "epoch: [1/1], step: [500/500], loss: 1.5233\n",
      "--- epoch: [1, 1]\n",
      "accuracy[test] : 47.270000 %\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "t = 0\n",
    "logger = {}\n",
    "logger['iteration'] = []\n",
    "logger['loss_iteration'] = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(data_set.loader['train']):\n",
    "        # get data to train\n",
    "        images = Variable(images.type(dtype_torch))\n",
    "        labels = Variable(labels.type(dtype_torch).long())\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.forward(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # reporting & logging\n",
    "        logger['iteration'] += [t]\n",
    "        logger['loss_iteration'] += [loss.data[0]]\n",
    "        t += 1\n",
    "        if t % 100 == 0:\n",
    "            print('epoch: [%d/%d], step: [%d/%d], loss: %.4f' %\n",
    "                   (epoch + 1, num_epochs, i+1, len(data_set.dataset['train'])//batch_size, loss.data[0]))\n",
    "        \n",
    "    print('--- epoch: [%d, %d]' % (epoch + 1, num_epochs))\n",
    "    #make_test(data_set.loader, model, 'train')\n",
    "    make_test(data_set.loader, model, 'test')\n",
    "\n",
    "    # switch back to the training  mode\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoUAAAFQCAYAAADJMgTVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkjAolCRJEvD/AQxoO1EMhxkgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc17a07a9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(logger['iteration'], logger['loss_iteration'],'ob', label=\"loss\")\n",
    "\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that CUDA is properly configured and you have a GPU available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_gpu = copy.deepcopy(model).type(dtype_torch_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variable for CPU ( as usual )\n",
    "x = torch.randn(128, 3, 32, 32).type(dtype_torch)\n",
    "x_var = Variable(x.type(dtype_torch)) # Construct a PyTorch Variable out of your input data\n",
    "\n",
    "# and now for GPU\n",
    "x_gpu = torch.randn(128, 3, 32, 32).type(dtype_torch_cuda)\n",
    "x_var_gpu = Variable(x.type(dtype_torch_cuda)) # Construct a PyTorch Variable out of your input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 6.49 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "yyy = model(x_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 416.86 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1 loops, best of 3: 1.46 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "torch.cuda.synchronize() # make sure there are no pending GPU computations\n",
    "yyy = model_gpu(x_var_gpu) \n",
    "torch.cuda.synchronize() # make sure there are no pending GPU computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion_gpu = nn.CrossEntropyLoss().type(dtype_torch_cuda)\n",
    "optimizer_gpu = torch.optim.Adam(model_gpu.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: [1/10], step: [100/500], loss: 10661.1104\n",
      "epoch: [1/10], step: [200/500], loss: 37117.7773\n",
      "epoch: [1/10], step: [300/500], loss: 64515.1016\n",
      "epoch: [1/10], step: [400/500], loss: 131198.7656\n",
      "epoch: [1/10], step: [500/500], loss: 185517.4531\n",
      "--- epoch: [1, 10]\n",
      "accuracy[test] : 14.540000 %\n",
      "epoch: [2/10], step: [100/500], loss: 327276.4688\n",
      "epoch: [2/10], step: [200/500], loss: 253440.9531\n",
      "epoch: [2/10], step: [300/500], loss: 314021.1875\n",
      "epoch: [2/10], step: [400/500], loss: 275305.3750\n",
      "epoch: [2/10], step: [500/500], loss: 441624.2500\n",
      "--- epoch: [2, 10]\n",
      "accuracy[test] : 17.030000 %\n",
      "epoch: [3/10], step: [100/500], loss: 377274.1875\n",
      "epoch: [3/10], step: [200/500], loss: 244484.3594\n",
      "epoch: [3/10], step: [300/500], loss: 382759.9062\n",
      "epoch: [3/10], step: [400/500], loss: 491383.5938\n",
      "epoch: [3/10], step: [500/500], loss: 411129.1562\n",
      "--- epoch: [3, 10]\n",
      "accuracy[test] : 22.190000 %\n",
      "epoch: [4/10], step: [100/500], loss: 707571.3750\n",
      "epoch: [4/10], step: [200/500], loss: 511280.5312\n",
      "epoch: [4/10], step: [300/500], loss: 841206.1875\n",
      "epoch: [4/10], step: [400/500], loss: 650398.8125\n",
      "epoch: [4/10], step: [500/500], loss: 738193.1875\n",
      "--- epoch: [4, 10]\n",
      "accuracy[test] : 19.770000 %\n",
      "epoch: [5/10], step: [100/500], loss: 618647.5625\n",
      "epoch: [5/10], step: [200/500], loss: 596815.5000\n",
      "epoch: [5/10], step: [300/500], loss: 941804.1875\n",
      "epoch: [5/10], step: [400/500], loss: 732717.9375\n",
      "epoch: [5/10], step: [500/500], loss: 382590.2812\n",
      "--- epoch: [5, 10]\n",
      "accuracy[test] : 23.880000 %\n",
      "epoch: [6/10], step: [100/500], loss: 558393.2500\n",
      "epoch: [6/10], step: [200/500], loss: 675954.3750\n",
      "epoch: [6/10], step: [300/500], loss: 737935.2500\n",
      "epoch: [6/10], step: [400/500], loss: 648920.0625\n",
      "epoch: [6/10], step: [500/500], loss: 811817.4375\n",
      "--- epoch: [6, 10]\n",
      "accuracy[test] : 24.750000 %\n",
      "epoch: [7/10], step: [100/500], loss: 1059777.2500\n",
      "epoch: [7/10], step: [200/500], loss: 809079.1250\n",
      "epoch: [7/10], step: [300/500], loss: 658368.1875\n",
      "epoch: [7/10], step: [400/500], loss: 763580.3750\n",
      "epoch: [7/10], step: [500/500], loss: 1005194.5000\n",
      "--- epoch: [7, 10]\n",
      "accuracy[test] : 24.290000 %\n",
      "epoch: [8/10], step: [100/500], loss: 878607.0625\n",
      "epoch: [8/10], step: [200/500], loss: 769682.3750\n",
      "epoch: [8/10], step: [300/500], loss: 941954.8125\n",
      "epoch: [8/10], step: [400/500], loss: 933387.1250\n",
      "epoch: [8/10], step: [500/500], loss: 876438.7500\n",
      "--- epoch: [8, 10]\n",
      "accuracy[test] : 24.400000 %\n",
      "epoch: [9/10], step: [100/500], loss: 1208298.8750\n",
      "epoch: [9/10], step: [200/500], loss: 1148321.5000\n",
      "epoch: [9/10], step: [300/500], loss: 700376.8750\n",
      "epoch: [9/10], step: [400/500], loss: 1229588.7500\n",
      "epoch: [9/10], step: [500/500], loss: 1204279.8750\n",
      "--- epoch: [9, 10]\n",
      "accuracy[test] : 25.450000 %\n",
      "epoch: [10/10], step: [100/500], loss: 892657.6250\n",
      "epoch: [10/10], step: [200/500], loss: 907784.5625\n",
      "epoch: [10/10], step: [300/500], loss: 1192228.7500\n",
      "epoch: [10/10], step: [400/500], loss: 956768.8125\n",
      "epoch: [10/10], step: [500/500], loss: 1056925.0000\n",
      "--- epoch: [10, 10]\n",
      "accuracy[test] : 26.680000 %\n"
     ]
    }
   ],
   "source": [
    "# train gpu model\n",
    "t = 0\n",
    "logger = {}\n",
    "logger['iteration'] = []\n",
    "logger['loss_iteration'] = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(data_set.loader['train']):\n",
    "        # get data to train\n",
    "        images = Variable(images.type(dtype_torch_cuda))\n",
    "        labels = Variable(labels.type(dtype_torch_cuda).long())\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_gpu.forward(images)\n",
    "        loss = criterion_gpu(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_gpu.step()\n",
    "\n",
    "        # reporting & logging\n",
    "        logger['iteration'] += [t]\n",
    "        logger['loss_iteration'] += [loss.data[0]]\n",
    "        t += 1\n",
    "        if t % 100 == 0:\n",
    "            print('epoch: [%d/%d], step: [%d/%d], loss: %.4f' %\n",
    "                   (epoch + 1, num_epochs, i+1, len(data_set.dataset['train'])//batch_size, loss.data[0]))\n",
    "        \n",
    "    print('--- epoch: [%d, %d]' % (epoch + 1, num_epochs))\n",
    "    #make_test(data_set.loader, model_gpu, 'train')\n",
    "    make_test(data_set.loader, model_gpu, 'test', gpu=True)\n",
    "\n",
    "    # switch back to the training  mode\n",
    "    model_gpu.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the code provided above as guidance, and using the following PyTorch documentation, specify a model with the following architecture:\n",
    "\n",
    "* 7x7 Convolutional Layer with 32 filters and stride of 1\n",
    "* ReLU Activation Layer\n",
    "* Spatial Batch Normalization Layer\n",
    "* 2x2 Max Pooling layer with a stride of 2\n",
    "* Affine layer with 1024 output units\n",
    "* ReLU Activation Layer\n",
    "* Affine layer from 1024 input units to 10 outputs\n",
    "\n",
    "And finally, set up a **cross-entropy** loss function and the **RMSprop** learning rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure you're doing the right thing, use the following tool to check the dimensionality of your output (it should be 64 x 10, since our batches have size 64 and the output of the final affine layer should be 10, corresponding to our 10 classes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-9659752d86a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype_torch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype_torch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Construct a PyTorch Variable out of your input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_var\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;31m# Feed it through the model!\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Check to make sure what comes out of your model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_model' is not defined"
     ]
    }
   ],
   "source": [
    "## Now we're going to feed a random batch into the model you defined and make sure the output is the right size\n",
    "x = torch.randn(64, 3, 32, 32).type(dtype_torch)\n",
    "x_var = Variable(x.type(dtype_torch)) # Construct a PyTorch Variable out of your input data\n",
    "ans = new_model(x_var)        # Feed it through the model! \n",
    "\n",
    "# Check to make sure what comes out of your model\n",
    "# is the right dimensionality... this should be True\n",
    "# if you've done everything correctly\n",
    "np.array_equal(np.array(ans.size()), np.array([64, 10])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
