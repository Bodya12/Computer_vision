{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Colormap of the notebook:*\n",
    "\n",
    "* <span style=\"color:red\">assignment problem</span>. The red color indicates the task that should be done\n",
    "* <span style=\"color:green\">debugging</span>. The green tells you what is expected outcome. Its primarily goal to help you get the correct answer\n",
    "* <span style=\"color:blue\">hints</span>.\n",
    "\n",
    "Assignment 3 (Two layer network)\n",
    "======================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for compatability issues \n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to make interactive plotting possible\n",
    "%matplotlib inline\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make plots a bit nicer\n",
    "plt.matplotlib.rcParams.update({'font.size': 18, 'font.family': 'serif'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random seed settings\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# data type (useful to have in pytorch)\n",
    "dtype_np = np.float64\n",
    "dtype_torch = torch.FloatTensor\n",
    "# dtype = torch.cuda.FloatTensor # to run on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data (playground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data = np.loadtxt('data/toy_data/data_class_train.txt')\n",
    "dataX = data[:,0:2]\n",
    "dataY = data[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = data.shape[0]\n",
    "dim_in = 2 # two features\n",
    "dim_out = 3 # three classes\n",
    "\n",
    "n_train = int(n_samples * 0.7)\n",
    "n_test = n_samples - n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train-test partition\n",
    "perm = np.random.permutation(n_samples)\n",
    "train_indx = perm[:n_train]\n",
    "test_indx = perm[n_train:]\n",
    "\n",
    "dataX_train, dataY_train = dataX[train_indx,:], dataY[train_indx]\n",
    "dataX_test, dataY_test = dataX[test_indx,:], dataY[test_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize data\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(dataX_train[dataY_train==0,0], dataX_train[dataY_train==0,1],'ob', label=\"class1\")\n",
    "plt.plot(dataX_train[dataY_train==1,0], dataX_train[dataY_train==1,1],'og', label=\"class2\")\n",
    "plt.plot(dataX_train[dataY_train==2,0], dataX_train[dataY_train==2,1],'or', label=\"class3\")\n",
    "\n",
    "plt.plot(dataX_test[:,0], dataX_test[:,1],'xk', label=\"test\")\n",
    "\n",
    "plt.xlabel('feature #1')\n",
    "plt.ylabel('feature #2')\n",
    "plt.legend()\n",
    "plt.xlim(-9, 9)\n",
    "plt.ylim(-5, 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Two-layer Network (by hand)\n",
    "\n",
    "$$x_{hidden} = RELU(x  \\cdot W_1 + b_1)$$\n",
    "$$y_{pred} = x_{hidden} \\cdot W_2 + b_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim_hidden = 100 # hidden dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input \n",
    "x = Variable(torch.from_numpy(dataX_train).type(dtype_torch), requires_grad=False)\n",
    "y = Variable(torch.from_numpy(dataY_train).type(torch.LongTensor), requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Weights and biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **[PROBLEM I]**: </span>   \n",
    "<span style=\"color:red\"> Fill the missing part (weights and biases for the output layer) </span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randomly initialize weights\n",
    "w1_value = np.random.randn(dim_in, dim_hidden)\n",
    "w2_value = # YOUR CODE HERE\n",
    "\n",
    "# Randomly initialize biases\n",
    "b1_value = np.random.randn(dim_hidden)\n",
    "b2_value = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 = Variable(torch.from_numpy(w1_value).type(dtype_torch), requires_grad=True)\n",
    "w2 = Variable(torch.from_numpy(w2_value).type(dtype_torch), requires_grad=True)\n",
    "\n",
    "b1 = Variable(torch.from_numpy(b1_value).type(dtype_torch), requires_grad=True)\n",
    "b2 = Variable(torch.from_numpy(b2_value).type(dtype_torch), requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loss (we will use cross-entropy loss), see documentation for details http://pytorch.org/docs/master/nn.html#torch.nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* learning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "n_iteration = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **[PROBLEM II]**: </span>   \n",
    "<span style=\"color:red\"> Fill the missing part (last operation in forward pass to calculate *y_pred*) </span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = {}\n",
    "logger['iteration'] = []\n",
    "logger['loss_iteration'] = []\n",
    "\n",
    "for t in range(n_iteration):  \n",
    "    \n",
    "    # forward pass\n",
    "    x_hidden = x.mm(w1) + b1.expand(n_train, dim_hidden)\n",
    "    x_hidden_act = x_hidden.clamp(min=0) # apply RELU\n",
    "    y_pred = # YOUR CODE HERE\n",
    "    \n",
    "    # compute loss\n",
    "    loss = criterion(y_pred, y)\n",
    "\n",
    "    # backprop\n",
    "    loss.backward()\n",
    "\n",
    "    # update weights using gradient descent  \n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "    w2.data -= learning_rate * w2.grad.data\n",
    "    b1.data -= learning_rate * b1.grad.data\n",
    "    b2.data -= learning_rate * b2.grad.data\n",
    "    \n",
    "    # manually zero the gradients\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()\n",
    "    b1.grad.data.zero_()\n",
    "    b2.grad.data.zero_()  \n",
    "    \n",
    "    # reporting & logging       \n",
    "    if t % 100 == 0:\n",
    "        print(t, loss.data[0])\n",
    "        \n",
    "    logger['iteration'] += [t]\n",
    "    logger['loss_iteration'] += [loss.data[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\"> After visualizing the loss (cell below) you should see something like this </span>\n",
    "\n",
    "<img src=\"fig/loss_toy.png\" style=\"height:128px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(logger['iteration'], logger['loss_iteration'],'ob', label=\"loss\")\n",
    "\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **[PROBLEM III]**: </span>   \n",
    "<span style=\"color:red\"> Implement the fuction which takes x and predicts its class </span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x, w1, b1, w2, b2, dtype_torch=torch.FloatTensor):\n",
    "    \"\"\"\n",
    "    Prediction based on two-layer model (by hand)\n",
    "    \n",
    "    Args:\n",
    "        x (numpy.array): sample\n",
    "        w1, b1, w2, b2 (torch.Tensor) : weights and biases \n",
    "    Returns:\n",
    "        scalar: predicted class\n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\"> by running the following command you should get number bigger than 8 </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(np.equal([predict(x, w1, b1, w2, b2) for x in dataX_train[:10]], [0, 2, 0, 1, 0, 2, 0, 0, 1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate accuracy given y and y_predicted\n",
    "    \n",
    "    Args:\n",
    "        y (numpy.array): ground truth\n",
    "        y_pred (numpy.array): predictated values\n",
    "         \n",
    "    Returns:\n",
    "        scalar: accuracy\n",
    "    \"\"\"\n",
    "    n_samples = y.shape[0]\n",
    "    return np.sum(y == y_pred)/n_samples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_predict = np.zeros(n_train)\n",
    "for i in range(n_train):\n",
    "    y_train_predict[i] = predict(dataX_train[i], w1, b1, w2, b2)\n",
    "\n",
    "print(\"Train accuracy: %f\" % get_accuracy(y_train_predict, dataY_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **[PROBLEM IV]**: </span>   \n",
    "<span style=\"color:red\"> Calculate accuracy on the test set </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Visualize decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Nspace = 100\n",
    "x1space = np.linspace(-9, 9, Nspace)\n",
    "x2space = np.linspace(-5, 12, Nspace)\n",
    "X,Y = np.meshgrid(x1space, x2space)\n",
    "\n",
    "Z = np.zeros((Nspace,Nspace))\n",
    "for i in range(Nspace):\n",
    "    for j in range(Nspace):\n",
    "        x1 = x1space[j]\n",
    "        y1 = x2space[i]\n",
    "        x = np.array([x1,y1])\n",
    "        Z[i,j] = predict(x, w1, b1, w2, b2)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.pcolor(X, Y, Z, vmin=abs(Z).min(), vmax=abs(Z).max())\n",
    "\n",
    "plt.xlabel('feature #1')\n",
    "plt.ylabel('feature #2')\n",
    "plt.xlim(-9, 9)\n",
    "plt.ylim(-5, 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Two-layer Network, again ...  (with nn package) \n",
    "\n",
    "$$x_{hidden} = RELU(x  \\cdot W_1 + b_1)$$\n",
    "$$y_{pred} = x_{hidden} \\cdot W_2 + b_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some hard work we will use torch with all its power and elegance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the nn package to define our model as a sequence of layers.\n",
    "# nn.Sequential is a Module which contains other Modules,\n",
    "# and applies them in sequence to produce its output.\n",
    "# Each Linear Module computes output from input using a linear function,\n",
    "# and holds internal Variables for its weight and bias.\n",
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim_in, dim_hidden),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(dim_hidden, dim_out),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loss (we will use cross-entropy loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input \n",
    "x = Variable(torch.from_numpy(dataX_train).type(dtype_torch), requires_grad=False)\n",
    "y = Variable(torch.from_numpy(dataY_train).type(torch.LongTensor), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "n_iteration = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger = {}\n",
    "logger['iteration'] = []\n",
    "logger['loss_iteration'] = []\n",
    "\n",
    "for t in range(n_iteration):  \n",
    "    \n",
    "    # forward pass\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    # compute loss\n",
    "    loss = criterion(y_pred, y)\n",
    "\n",
    "    # backprop\n",
    "    loss.backward()\n",
    "\n",
    "    # update weights using gradient descent  \n",
    "    for param in model.parameters():\n",
    "        param.data -= learning_rate * param.grad.data \n",
    "    \n",
    "    # manually zero the gradients\n",
    "    model.zero_grad()  \n",
    "    \n",
    "    # reporting & logging       \n",
    "    if t % 100 == 0:\n",
    "        print(t, loss.data[0])\n",
    "        \n",
    "    logger['iteration'] += [t]\n",
    "    logger['loss_iteration'] += [loss.data[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(logger['iteration'], logger['loss_iteration'],'ob', label=\"loss\")\n",
    "\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x, model):\n",
    "    \"\"\"\n",
    "    Prediction based on two-layer model\n",
    "    \n",
    "    Args:\n",
    "        x (numpy.array): feature vector of a sample\n",
    "         \n",
    "    Returns:\n",
    "        scalar: predicted class for this sample\n",
    "    \"\"\"    \n",
    "    t = Variable(torch.from_numpy(x).type(dtype_torch))\n",
    "    forward_pass = model(t)\n",
    "    return np.argmax(forward_pass.data.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_predict = predict(dataX_train,model)\n",
    "print(\"Train accuracy: %f\" % get_accuracy(y_train_predict, dataY_train))\n",
    "\n",
    "y_test_predict = predict(dataX_test, model)\n",
    "print(\"Test accuracy: %f\" % get_accuracy(y_test_predict, dataY_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Two-layer Network, again and again ...  (with nn package + optim ) \n",
    "\n",
    "$$x_{hidden} = RELU(x  \\cdot W_1 + b_1)$$\n",
    "$$y_{pred} = x_{hidden} \\cdot W_2 + b_2$$\n",
    "\n",
    "torch.optim is a package implementing various optimization algorithms.  \n",
    "see official documentation: http://pytorch.org/docs/master/optim.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already familar stuff ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim_in, dim_hidden),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(dim_hidden, dim_out),\n",
    "        )\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# input \n",
    "x = Variable(torch.from_numpy(dataX_train).type(dtype_torch), requires_grad=False)\n",
    "y = Variable(torch.from_numpy(dataY_train).type(torch.LongTensor), requires_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of doing manually gradient descent, we will ask optim package to do the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "n_iteration = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger = {}\n",
    "logger['iteration'] = []\n",
    "logger['loss_iteration'] = []\n",
    "\n",
    "for t in range(n_iteration):  \n",
    "    \n",
    "    # forward + backward + optimize\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    loss = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()  \n",
    "    \n",
    "    # reporting & logging       \n",
    "    if t % 100 == 0:\n",
    "        print(t, loss.data[0])\n",
    "        \n",
    "    logger['iteration'] += [t]\n",
    "    logger['loss_iteration'] += [loss.data[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(logger['iteration'], logger['loss_iteration'],'ob', label=\"loss\")\n",
    "\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-layer Network for our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.data_set import DataSetCifar10, DataSetDTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do it for sanity check (that you have a dataset)\n",
    "!./data/get_cifar10_dataset.sh # for cifar10\n",
    "#!./data/get_dtd_dataset.sh # for dtd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data = 'data' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim_hidden = 500\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose one the courses datasets (cifar10 or DTD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = DataSetCifar10(path_data, num_dunkeys=4, batch_size=batch_size)\n",
    "#data_set = DataSetDTD(path_data, num_dunkeys=4, batch_size=100, fin_scale=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make more clear what comes next:\n",
    "\n",
    "Our image data (obtained from dataloader) has the following shape N x C x H x W, where:\n",
    "* N is the number of datapoints\n",
    "* C is the number of channels\n",
    "* H is the height of the intermediate feature map in pixels\n",
    "* W is the height of the intermediate feature map in pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# useful function \n",
    "def make_test(data_loader, model_current, train_test):\n",
    "    \"\"\"\n",
    "     Giving dataset and model function calculates and prints out the accuracy\n",
    "    \n",
    "    Args:\n",
    "        data_loader (DataLoader): loaded dataset\n",
    "        model_current (model): the current model\n",
    "        train_test (string): either 'train' or 'test' to define on which of these datasets we calculate accuracy\n",
    "         \n",
    "    Returns:\n",
    "        scalar: accuracy value\n",
    "    \"\"\"    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images_, labels_ in data_loader[train_test]:\n",
    "        N, C, H, W = images_.size() # read in N, C, H, W, C, H, W = x.size() # read in N, C, H, W\n",
    "        images_ = Variable(images_.view(N, -1))\n",
    "        outputs_ = model_current(images_)\n",
    "        _, predicted = torch.max(outputs_.data, 1)\n",
    "        total += labels_.size(0)\n",
    "        correct += (predicted == labels_).sum()\n",
    "    print('accuracy[' + train_test + '] : %f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **[PROBLEM V]**: </span>   \n",
    "<span style=\"color:red\"> Correctly specify the dimensions of the model </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(# YOUR CODE HERE),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(# YOUR CODE HERE),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* define optimizer (we will use 'Adam' here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train\n",
    "t = 0\n",
    "logger = {}\n",
    "logger['iteration'] = []\n",
    "logger['loss_iteration'] = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(data_set.loader['train']):\n",
    "        # get data to train\n",
    "        N, C, H, W = images.size() # read in N, C, H, W, C, H, W = x.size() # read in N, C, H, W\n",
    "        images = Variable(images.view(N, -1))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.forward(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # reporting & logging\n",
    "        logger['iteration'] += [t]\n",
    "        logger['loss_iteration'] += [loss.data[0]]\n",
    "        t += 1\n",
    "        if t % 100 == 0:\n",
    "            print('epoch: [%d/%d], step: [%d/%d], loss: %.4f' %\n",
    "                   (epoch + 1, num_epochs, i+1, len(data_set.dataset['train'])//batch_size, loss.data[0]))\n",
    "        \n",
    "    print('--- epoch: [%d, %d]' % (epoch + 1, num_epochs))\n",
    "    #make_test(data_set.loader, model, 'train')\n",
    "    make_test(data_set.loader, model, 'test')\n",
    "\n",
    "    # switch back to the training  mode\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(logger['iteration'], logger['loss_iteration'],'ob', label=\"loss\")\n",
    "\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
