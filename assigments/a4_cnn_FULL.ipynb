{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Colormap of the notebook:*\n",
    "\n",
    "* <span style=\"color:red\">assignment problem</span>. The red color indicates the task that should be done\n",
    "* <span style=\"color:green\">debugging</span>. The green tells you what is expected outcome. Its primarily goal to help you get the correct answer\n",
    "* <span style=\"color:blue\">hints</span>.\n",
    "\n",
    "Assignment 4 (Convolutional Neural Network)\n",
    "======================\n",
    "\n",
    "partially based on 'PyTorch.ipynb' from assignment 2 in cs231 course.  \n",
    "http://cs231n.github.io/assignments2017/assignment2/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch supports many layer types, loss functions, and optimizers\n",
    "\n",
    "* Layers: http://pytorch.org/docs/nn.html\n",
    "* Activations: http://pytorch.org/docs/nn.html#non-linear-activations\n",
    "* Loss functions: http://pytorch.org/docs/nn.html#loss-functions\n",
    "* Optimizers: http://pytorch.org/docs/optim.html#algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for compatability issues \n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to make interactive plotting possible\n",
    "%matplotlib inline\n",
    "# for auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make plots a bit nicer\n",
    "plt.matplotlib.rcParams.update({'font.size': 18, 'font.family': 'serif'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random seed settings\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# data type\n",
    "dtype_np = np.float64\n",
    "dtype_torch = torch.FloatTensor\n",
    "dtype_torch_cuda = torch.cuda.FloatTensor # to run on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.data_set import DataSetCifar10, DataSetDTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do it for sanity check (that you have a dataset)\n",
    "!./data/get_cifar10_dataset.sh # for cifar10\n",
    "#!./data/get_dtd_dataset.sh # for dtd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data = 'data' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = DataSetCifar10(path_data, num_dunkeys=4, batch_size=batch_size)\n",
    "#data_set = DataSetDTD(path_data, num_dunkeys=4, batch_size=100, fin_scale=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_test(data_loader, model_current, train_test, gpu=False):\n",
    "    \"\"\"\n",
    "     Giving dataset and model function calculates and prints out the accuracy\n",
    "    \n",
    "    Args:\n",
    "        data_loader (DataLoader): loaded dataset\n",
    "        model_current (model): the current model\n",
    "        train_test (string): either 'train' or 'test' to define on which of these datasets we calculate accuracy\n",
    "        gpu (bool): flag to indicate if our model runs on gpu\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images_, labels_ in data_loader[train_test]:\n",
    "        \n",
    "        if gpu:\n",
    "            images_ = Variable(images_.type(dtype_torch_cuda), volatile=True)\n",
    "            outputs_ = model_current(images_)\n",
    "            _, predicted = torch.max(outputs_.data.cpu(), 1)\n",
    "        else:\n",
    "            images_ = Variable(images_)\n",
    "            outputs_ = model_current(images_)\n",
    "            _, predicted = torch.max(outputs_.data, 1)\n",
    "            \n",
    "        total += labels_.size(0)\n",
    "        correct += (predicted == labels_).sum()\n",
    "    print('accuracy[' + train_test + '] : %f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that our image data (and intermediate feature maps) are initially N x C x H x W, where:\n",
    "* N is the number of datapoints\n",
    "* C is the number of channels\n",
    "* H is the height of the intermediate feature map in pixels\n",
    "* W is the height of the intermediate feature map in pixels\n",
    "\n",
    "we use a \"Flatten\" operation to collapse the C x H x W values per representation into a single long vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here's where we define the architecture of the model... \n",
    "first_model = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, kernel_size=7, stride=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                Flatten(), # see above for explanation\n",
    "                nn.Linear(5408, 10), # affine layer\n",
    "              )\n",
    "\n",
    "# Set the type of all data in this model to be FloatTensor \n",
    "first_model.type(dtype_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = copy.deepcopy(first_model).type(dtype_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().type(dtype_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train\n",
    "t = 0\n",
    "logger = {}\n",
    "logger['iteration'] = []\n",
    "logger['loss_iteration'] = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(data_set.loader['train']):\n",
    "        # get data to train\n",
    "        images = Variable(images.type(dtype_torch))\n",
    "        labels = Variable(labels.type(dtype_torch).long())\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.forward(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # reporting & logging\n",
    "        logger['iteration'] += [t]\n",
    "        logger['loss_iteration'] += [loss.data[0]]\n",
    "        t += 1\n",
    "        if t % 100 == 0:\n",
    "            print('epoch: [%d/%d], step: [%d/%d], loss: %.4f' %\n",
    "                   (epoch + 1, num_epochs, i+1, len(data_set.dataset['train'])//batch_size, loss.data[0]))\n",
    "        \n",
    "    print('--- epoch: [%d, %d]' % (epoch + 1, num_epochs))\n",
    "    #make_test(data_set.loader, model, 'train')\n",
    "    make_test(data_set.loader, model, 'test')\n",
    "\n",
    "    # switch back to the training  mode\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(logger['iteration'], logger['loss_iteration'],'ob', label=\"loss\")\n",
    "\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify that CUDA is properly configured and you have a GPU available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_gpu = copy.deepcopy(model).type(dtype_torch_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variable for CPU ( as usual )\n",
    "x = torch.randn(128, 3, 32, 32).type(dtype_torch)\n",
    "x_var = Variable(x.type(dtype_torch)) # Construct a PyTorch Variable out of your input data\n",
    "\n",
    "# and now for GPU\n",
    "x_gpu = torch.randn(128, 3, 32, 32).type(dtype_torch_cuda)\n",
    "x_var_gpu = Variable(x.type(dtype_torch_cuda)) # Construct a PyTorch Variable out of your input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit \n",
    "yyy = model(x_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit \n",
    "torch.cuda.synchronize() # make sure there are no pending GPU computations\n",
    "yyy = model_gpu(x_var_gpu) \n",
    "torch.cuda.synchronize() # make sure there are no pending GPU computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion_gpu = nn.CrossEntropyLoss().type(dtype_torch_cuda)\n",
    "optimizer_gpu = torch.optim.Adam(model_gpu.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train gpu model\n",
    "t = 0\n",
    "logger = {}\n",
    "logger['iteration'] = []\n",
    "logger['loss_iteration'] = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(data_set.loader['train']):\n",
    "        # get data to train\n",
    "        images = Variable(images.type(dtype_torch_cuda))\n",
    "        labels = Variable(labels.type(dtype_torch_cuda).long())\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        optimizer_gpu.zero_grad()\n",
    "        outputs = model_gpu.forward(images)\n",
    "        loss = criterion_gpu(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_gpu.step()\n",
    "\n",
    "        # reporting & logging\n",
    "        logger['iteration'] += [t]\n",
    "        logger['loss_iteration'] += [loss.data[0]]\n",
    "        t += 1\n",
    "        if t % 100 == 0:\n",
    "            print('epoch: [%d/%d], step: [%d/%d], loss: %.4f' %\n",
    "                   (epoch + 1, num_epochs, i+1, len(data_set.dataset['train'])//batch_size, loss.data[0]))\n",
    "        \n",
    "    print('--- epoch: [%d, %d]' % (epoch + 1, num_epochs))\n",
    "    #make_test(data_set.loader, model_gpu, 'train')\n",
    "    make_test(data_set.loader, model_gpu, 'test', gpu=True)\n",
    "\n",
    "    # switch back to the training  mode\n",
    "    model_gpu.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **[PROBLEM]**: </span>  \n",
    "<span style=\"color:red\"> Using the code provided above as guidance, </span>  \n",
    "<span style=\"color:red\"> and using the following PyTorch documentation, specify a model with the following architecture: </span>  \n",
    "\n",
    "<span style=\"color:red\"> - 7x7 Convolutional Layer with 32 filters and stride of 1 </span>  \n",
    "<span style=\"color:red\"> - ReLU Activation Layer </span>  \n",
    "<span style=\"color:red\"> - BatchNorm2D (spatial batch normalization) </span>  \n",
    "<span style=\"color:red\"> - 2x2 Max Pooling layer with a stride of 2 </span>  \n",
    "<span style=\"color:red\"> - Affine layer with 1024 output units </span>  \n",
    "<span style=\"color:red\"> - ReLU Activation Layer </span>  \n",
    "<span style=\"color:red\"> - Affine layer from 1024 input units to 10 outputs </span>  \n",
    "<span style=\"color:red\"> - And finally, set up a **cross-entropy** loss function and the **RMSprop** learning rule. </span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> To make sure you're doing the right thing, use the following tool to check the dimensionality of your output (it should be 64 x 10, since our batches have size 64 and the output of the final affine layer should be 10, corresponding to our 10 classes): </span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_model = nn.Sequential( nn.Conv2d(3, 32, kernel_size=7, stride=2),\n",
    "                           nn.ReLU(inplace=True),\n",
    "                           nn.BatchNorm2d(32),\n",
    "                           nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                           Flatten(),\n",
    "                           nn.Linear(6 * 6 * 32, 1024),\n",
    "                           nn.ReLU(inplace=True),\n",
    "                           nn.Linear(1024, 10)\n",
    "                         )\n",
    "\n",
    "model_gpu = copy.deepcopy(new_model).type(dtype_torch_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = torch.randn(64, 3, 32, 32).type(dtype_torch_cuda)\n",
    "x_var = Variable(x.type(dtype_torch_cuda)) \n",
    "ans = model_gpu(x_var)        \n",
    "\n",
    "# Check to make sure what comes out of your model\n",
    "# is the right dimensionality... this should be True\n",
    "# if you've done everything correctly\n",
    "np.array_equal(np.array(ans.size()), np.array([64, 10])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "num_epochs = 30\n",
    "\n",
    "criterion_gpu = nn.CrossEntropyLoss().type(dtype_torch_cuda)\n",
    "optimizer_gpu = torch.optim.Adam(model_gpu.parameters(), lr=learning_rate)\n",
    "\n",
    "# train gpu model\n",
    "t = 0\n",
    "logger = {}\n",
    "logger['iteration'] = []\n",
    "logger['loss_iteration'] = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(data_set.loader['train']):\n",
    "        # get data to train\n",
    "        images = Variable(images.type(dtype_torch_cuda))\n",
    "        labels = Variable(labels.type(dtype_torch_cuda).long())\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        optimizer_gpu.zero_grad()\n",
    "        outputs = model_gpu.forward(images)\n",
    "        loss = criterion_gpu(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_gpu.step()\n",
    "\n",
    "        # reporting & logging\n",
    "        logger['iteration'] += [t]\n",
    "        logger['loss_iteration'] += [loss.data[0]]\n",
    "        t += 1\n",
    "        if t % 100 == 0:\n",
    "            print('epoch: [%d/%d], step: [%d/%d], loss: %.4f' %\n",
    "                   (epoch + 1, num_epochs, i+1, len(data_set.dataset['train'])//batch_size, loss.data[0]))\n",
    "        \n",
    "    print('--- epoch: [%d, %d]' % (epoch + 1, num_epochs))\n",
    "    make_test(data_set.loader, model_gpu, 'train')\n",
    "    make_test(data_set.loader, model_gpu, 'test', gpu=True)\n",
    "\n",
    "    # switch back to the training  mode\n",
    "    model_gpu.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tips from *cs231 course*\n",
    "\n",
    "### Things you should try:\n",
    "- **Filter size**: Above we used 7x7; this makes pretty pictures but smaller filters may be more efficient\n",
    "- **Number of filters**: Above we used 32 filters. Do more or fewer do better?\n",
    "- **Pooling vs Strided Convolution**: Do you use max pooling or just stride convolutions?\n",
    "- **Batch normalization**: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster?\n",
    "- **Network architecture**: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include:\n",
    "    - [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax or SVM]\n",
    "- **Global Average Pooling**: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in [Google's Inception Network](https://arxiv.org/abs/1512.00567) (See Table 1 for their architecture).\n",
    "- **Regularization**: Add l2 weight regularization, or perhaps use Dropout.\n",
    "\n",
    "### Tips for training\n",
    "For each network architecture that you try, you should tune the learning rate and regularization strength. When doing this there are a couple important things to keep in mind:\n",
    "\n",
    "- If the parameters are working well, you should see improvement within a few hundred iterations\n",
    "- Remember the coarse-to-fine approach for hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all.\n",
    "- Once you have found some sets of parameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n",
    "\n",
    "### Going above and beyond\n",
    "If you are feeling adventurous there are many other features you can implement to try and improve your performance. \n",
    "\n",
    "- Alternative update steps: For the assignment we implemented SGD+momentum, RMSprop, and Adam; you could try alternatives like AdaGrad or AdaDelta.\n",
    "- Alternative activation functions such as leaky ReLU, parametric ReLU, ELU, or MaxOut.\n",
    "- Model ensembles\n",
    "- Data augmentation\n",
    "- New Architectures\n",
    "  - [ResNets](https://arxiv.org/abs/1512.03385) where the input from the previous layer is added to the output.\n",
    "  - [DenseNets](https://arxiv.org/abs/1608.06993) where inputs into previous layers are concatenated together.\n",
    "  - [This blog has an in-depth overview](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
